# -*- coding: utf-8 -*-
#!/usr/bin/env python3
import rospy
from duckietown.dtros import DTROS, TopicType, NodeType
from sensor_msgs.msg import CompressedImage
from std_msgs.msg import String
import rospkg

import numpy as np
import sys, os, distutils.core
import math
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions
import torch, detectron2
import detectron2
from detectron2.utils.logger import setup_logger
import cv2, random, json
from detectron2.utils.visualizer import ColorMode
import rosbag

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.structures import BoxMode
from detectron2.engine import DefaultTrainer

"""Detectron2-Duckiebot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11jrZvjetAeoH7LiuMAOxTGTf1TEKwStf
"""

OUTPUT_MODEL_PATH = "/content/output/model_final.pth" # "/content/drive/MyDrive/CMPUT412/Project/model_final.pth"
BAG_FILE_PATH = "/content/drive/MyDrive/CMPUT412/Project/more_dataset_gen.bag"  # a bag file not in training set, for testing

TIME_CUTOFF_MIN = 0 # 1681175162 #1681175159791011507
TIME_CUTOFF_MAX = math.inf # 1680653588


HOST_NAME = os.environ["VEHICLE_NAME"]


class Detectron2_Duckiebot(DTROS):

    def __init__(self,node_name):

        super(Detectron2_Duckiebot, self).__init__(node_name=node_name, node_type=NodeType.GENERIC)
        
        self.sub = rospy.Subscriber(f'/{HOST_NAME}/camera_node/image/compressed', CompressedImage, self.callback)
        self.pub = rospy.Publisher(f'/{HOST_NAME}/detectron2_duckiebot/detected_objects', String, queue_size=1)
        self.img_pub = rospy.Publisher(f'/{HOST_NAME}/camera_node/image/object_detection/compressed', CompressedImage, queue_size=1)
        self.veh = str(os.environ["VEHICLE_NAME"])
        self.seq = 0 

        self.image = None
        self.rospack = rospkg.RosPack()
        self.path = self.rospack.get_path("detectron2_duckiebot_node")
        """Detection Network variables"""

        TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
        CUDA_VERSION = torch.__version__.split("+")[-1]
        print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
        print("detectron2:", detectron2.__version__)

        # Some basic setup:
        # Setup detectron2 logger
        setup_logger()  

        self.cfg = get_cfg()

        DatasetCatalog.clear()
        for d in ["train"]:
            MetadataCatalog.get("duckie_" + d).set(thing_classes=["duck", "duckiebot"])
        self.duckie_metadata = MetadataCatalog.get("duckie_train")

    def callback(self, msg):
        # how to decode compressed image
        # reference: http://wiki.ros.org/rospy_tutorials/Tutorials/WritingImagePublisherSubscriber
        compressed_image = np.frombuffer(msg.data, np.uint8)
        im = cv2.imdecode(compressed_image, cv2.IMREAD_COLOR)
        self.image = im

    def send_compressed(self,pub, seq, frame_id, im):
        msg = CompressedImage()
        msg.header.seq = seq
        msg.header.stamp = rospy.Time.now()
        msg.header.frame_id = frame_id
        msg.format = 'jpeg'
        ret, buffer = cv2.imencode('.jpg', im)
        if not ret:
            print('failed to encode image!')
        else:
            msg.data = np.array(buffer).tostring()
            pub.publish(msg)
        return ret
    
    def install(self):

        """# Install detectron2"""

        os.system("python -m pip install pyyaml==5.1")
        # Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.
        # See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions
        os.path("!git clone 'https://github.com/facebookresearch/detectron2'")
        dist = distutils.core.run_setup("./detectron2/setup.py")
        os.path("!python -m pip install {' '.join([f"'{x}'" for x in dist.install_requires])}")
        sys.path.insert(0, os.path.abspath('./detectron2'))

    def fine_tune_model(self):

        """

        Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.

        """

        self.cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
        self.cfg.DATASETS.TRAIN = ("duckie_train",)
        self.cfg.DATASETS.TEST = ()
        self.cfg.DATALOADER.NUM_WORKERS = 2
        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
        self.cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real "batch size" commonly known to deep learning people
        self.cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR
        self.cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
        self.cfg.SOLVER.STEPS = []        # do not decay learning rate
        self.cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
        self.cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
        # NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.  
        
    def inference(self):

        """## Inference & evaluation using the trained model
        """
        # Inference should use the config with parameters that are used in training
        # cfg now already contains everything we've set previously. We changed it a little bit for inference:
        self.cfg.MODEL.WEIGHTS = os.path.join(self.cfg.OUTPUT_DIR, OUTPUT_MODEL_PATH)  # path to the model we just trained
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold
        self.predictor = DefaultPredictor(self.cfg)

    def publish_detections(self):

        outputs = self.predictor(self.image)
        v = Visualizer(self.image[:, :, ::-1],
                    metadata=self.duckie_metadata, 
                    scale=0.5, 
                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models
        )
        print(outputs)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        ret = self.send_compressed(self.img_pub, self.seq, f'{HOST_NAME}/camera_optical_frame', out.get_image()[:, :, ::-1])
        if ret:
            self.seq += 1

        pred_boxes = outputs["instances"]["pred_boxes"]
        scores = outputs["instances"]["scores"]
        pred_classes = outputs["instances"]["pred_classes"]

        msg = {'class':pred_classes,'pred_boxes': pred_boxes, 'scores': scores}
        self.pub(String(json.dumps(msg)))

if __name__ == '__main__':
    detect_node = Detectron2_Duckiebot("detectron2_duckiebot")

    """ run the first time you run this code, to install detectron2 """
    detect_node.install()

    detect_node.fine_tune_model()

    detect_node.inference()

    detect_node.publish_detections()

# image_count = 0
# for topic, msg, t in bag.read_messages(topics=[f'/{HOST_NAME}/camera_node/image/compressed']):
#     if t.secs < TIME_CUTOFF_MIN:
#         continue
#     elif t.secs > TIME_CUTOFF_MAX:
#         break
    
#     image_count += 1

#     if image_count % 20 != 0:
#         continue
#     im = cv2.imdecode(np.frombuffer(msg.data, np.uint8), cv2.IMREAD_COLOR)

    
    
#     if image_count >= 1800:
#         print(t)
#         break